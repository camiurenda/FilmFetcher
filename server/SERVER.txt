================================================================
Repopack Output File
================================================================

This file was generated by Repopack on: 2024-11-02T19:24:23.583Z

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This header section
2. Repository structure
3. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
1. This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
2. When processing this file, use the separators and "File:" markers to
  distinguish between different files in the repository.
3. Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repopack's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.



For more information about Repopack, visit: https://github.com/yamadashy/repopack

================================================================
Repository Structure
================================================================
api/index.js
app.js
models/projection.model.js
models/scrapingHistory.model.js
models/site.model.js
package.json
routes/projection.routes.js
routes/site.routes.js
routes/stats.routes.js
services/imagescraping.service.js
services/pdfscraping.service.js
services/scraping.service.js
vercel.json

================================================================
Repository Files
================================================================

================
File: api/index.js
================
const express = require('express');
const cors = require('cors');
const morgan = require('morgan');
const mongoose = require('mongoose');
const { auth, requiresAuth } = require('express-openid-connect');
const siteRoutes = require('../routes/site.routes');
const projectionRoutes = require('../routes/projection.routes');
const ScrapingService = require('../services/scraping.service'); 
const statsRoutes = require('../routes/stats.routes');

require('dotenv').config();

const config = {
  authRequired: false,
  auth0Logout: true,
  secret: process.env.SECRET,
  baseURL: process.env.BASE_URL,
  clientID: process.env.CLIENT_ID,
  issuerBaseURL: process.env.ISSUER_BASE_URL
};

const app = express();

morgan.token('custom-log', (req, res) => {
  if (res.locals.customLog) {
    const log = res.locals.customLog;
    res.locals.customLog = '';
    return log;
  }
  return '';
});

app.use(morgan(':method :url :status :response-time ms :custom-log'));
app.use(express.json());
app.use(auth(config));

const allowedOrigins = [
  'http://localhost:3000',
  'http://localhost:5000',
  'https://film-fetcher-eta.vercel.app',
  'https://film-fetcher-exc9.vercel.app',
  'https://filmfetcher.onrender.com/'
];

app.use(cors({
  origin: function(origin, callback) {
    if (!origin) return callback(null, true);
    if (allowedOrigins.indexOf(origin) === -1) {
      var msg = 'The CORS policy for this site does not allow access from the specified Origin.';
      return callback(new Error(msg), false);
    }
    return callback(null, true);
  },
  credentials: true
}));

app.use('/api', siteRoutes);
app.use('/api/sites', siteRoutes);
app.use('/api/projections', projectionRoutes);
app.use('/api/stats', statsRoutes);

const originalConsoleLog = console.log;
console.log = (...args) => {
  if (args.length) {
    const log = args.map(arg => 
      typeof arg === 'object' ? JSON.stringify(arg) : arg
    ).join(' ');
    if (global.currentResponse) {
      global.currentResponse.locals.customLog = (global.currentResponse.locals.customLog || '') + log + '\n';
    }
  }
  originalConsoleLog.apply(console, args);
};

app.get('/', (req, res) => {
  res.send('Servidor funcionando!!!');
});

app.get('/profile', requiresAuth(), (req, res) => {
  res.send(JSON.stringify(req.oidc.user));
});

app.get('/protected', requiresAuth(), (req, res) => {
  res.send('¡Esta ruta está protegida!');
});

app.get('/api/test', (req, res) => {
  res.json({ message: 'El backend de Film Fetcher está funcionando correctamente.' });
});

// Inicialización de servicios
const initializeServices = async () => {
  try {
    await mongoose.connect(process.env.MONGO_DB_URI, {});
    console.log('Conectado exitosamente a MongoDB');
    await ScrapingService.initializeJobs();
    console.log('Trabajos de scraping inicializados');
  } catch (err) {
    console.error('Error durante la inicialización:', err);
  }
};

initializeServices();

module.exports = app;

================
File: app.js
================
const app = require('./api/index');

const PORT = process.env.PORT || 5000;
app.listen(PORT, () => {
  console.log(`Servidor iniciado en el puerto ${PORT}`);
});

================
File: models/projection.model.js
================
const mongoose = require('mongoose');

const ProjectionSchema = new mongoose.Schema({
  nombrePelicula: {
    type: String,
    required: true,
  },
  fechaHora: {
    type: Date,
    required: true,
  },
  director: {
    type: String,
    default: 'No especificado',
  },
  genero: {
    type: String,
    default: 'No especificado',
  },
  duracion: {
    type: Number,
    default: 0,
  },
  sala: {
    type: String,
    default: '',
  },
  precio: {
    type: Number,
    default: 0,
  },
  habilitado: {
    type: Boolean,
    default: true,
  },
  fechaCreacion: {
    type: Date,
    default: Date.now,
  },
  cargaManual: {
    type: Boolean,
    default: false,
  },
  sitio: {
    type: mongoose.Schema.Types.ObjectId,
    ref: 'Sites',
    required: true,
  },
  nombreCine: {
    type: String,
    required: true,
  },
  claveUnica: {
    type: String,
    unique: true,
    required: true,
  }
});

ProjectionSchema.index({ nombrePelicula: 1, fechaHora: 1, sitio: 1 }, { unique: true });

ProjectionSchema.methods.generarClaveUnica = function() {
  return `${this.nombrePelicula}-${this.fechaHora.toISOString()}-${this.sitio}`;
};

ProjectionSchema.pre('save', async function(next) {
  if (!this.claveUnica) {
    this.claveUnica = this.generarClaveUnica();
  }
  if (!this.nombreCine && this.sitio) {
    const site = await mongoose.model('Sites').findById(this.sitio);
    if (site) {
      this.nombreCine = site.nombre;
    }
  }
  next();
});

module.exports = mongoose.model('Projection', ProjectionSchema);

================
File: models/scrapingHistory.model.js
================
const mongoose = require('mongoose');

const ScrapingHistorySchema = new mongoose.Schema({
  siteId: {
    type: mongoose.Schema.Types.ObjectId,
    ref: 'Sites',
    required: true
  },
  fechaScraping: {
    type: Date,
    default: Date.now
  },
  estado: {
    type: String,
    enum: ['exitoso', 'fallido'],
    default: 'exitoso'
  },
  mensajeError: {
    type: String
  },
  cantidadProyecciones: {
    type: Number,
    default: 0
  },
  respuestaOpenAI: {
    type: String
  },
  causaFallo: {
    type: String
  }
});

module.exports = mongoose.model('ScrapingHistory', ScrapingHistorySchema);

================
File: models/site.model.js
================
const mongoose = require('mongoose');

const SiteSchema = new mongoose.Schema({
  nombre: {
    type: String,
    required: true,
  },
  url: {
    type: String,
    required: true,
  },
  direccion: {
    type: String,
  },
  tipo: {
    type: String,
    enum: ['cine', 'teatro', 'museo'],
  },
  tipoCarga: {
    type: String,
    enum: ['scraping', 'manual'],
    required: true,
  },
  tipoArchivo: {
    type: String,
    enum: ['imagen', 'pdf'],
    required: function() { return this.tipoCarga === 'manual'; },
  },
  frecuenciaActualizacion: {
    type: String,
    enum: ['diaria', 'semanal', 'mensual', 'test'],
    required: function() { return this.tipoCarga === 'scraping'; },
  },
  usuarioCreador: {
    type: String,
    required: true,
  },
  fechaCreacion: {
    type: Date,
    default: Date.now,
  },
  habilitado: {
    type: Boolean,
    default: true,
  },
  activoParaScraping: {
    type: Boolean,
    default: function() { return this.tipoCarga === 'scraping'; },
  }
});

module.exports = mongoose.model('Sites', SiteSchema);

================
File: package.json
================
{
  "name": "backend-cartelera",
  "version": "1.0.0",
  "main": "api/index.js",
  "scripts": {
    "start": "node app.js",
    "dev": "nodemon app.js",
    "build": "npm install"
  },
  "dependencies": {
    "axios": "^1.7.7",
    "cheerio": "^1.0.0",
    "chrome-aws-lambda": "^10.1.0",
    "chromium": "^3.0.3",
    "cors": "^2.8.5",
    "cron": "^3.1.7",
    "dotenv": "^16.4.5",
    "express": "^4.18.2",
    "express-openid-connect": "^2.8.0",
    "groq-sdk": "^0.7.0",
    "json2csv": "^6.0.0-alpha.2",
    "mongoose": "^8.6.1",
    "morgan": "^1.10.0",
    "node": "^22.8.0",
    "node-cron": "^3.0.3",
    "node-telegram-bot-api": "^0.66.0",
    "openai": "^4.68.1",
    "pdf-parse": "^1.1.1",
    "puppeteer": "^23.6.0",
    "puppeteer-core": "^10.4.0",
    "qrcode": "^1.5.4",
    "qrcode-terminal": "^0.12.0",
    "websocket": "^1.0.35",
    "whatsapp-web.js": "^1.26.0"
  }
}

================
File: routes/projection.routes.js
================
const express = require('express');
const Projection = require('../models/projection.model');
const ScrapingService = require('../services/scraping.service');
const ImageScrapingService = require('../services/imagescraping.service');
const PDFScrapingService = require('../services/pdfscraping.service');
const Site = require('../models/site.model');
const router = express.Router();
const { Parser } = require('json2csv');

// Crear una nueva proyección
router.post('/add', async (req, res) => {
  try {
    const { nombrePelicula, fechaHora, sitio, director, genero, duracion, sala, precio } = req.body;

    // Validar campos requeridos
    if (!nombrePelicula || !fechaHora || !sitio) {
      return res.status(400).json({ message: 'Faltan campos requeridos: nombrePelicula, fechaHora y sitio son obligatorios' });
    }

    // Obtener el nombre del cine
    let siteInfo;
    try {
      siteInfo = await Site.findById(sitio);
      if (!siteInfo) {
        return res.status(404).json({ message: 'Sitio no encontrado' });
      }
    } catch (error) {
      console.error('Error al buscar el sitio:', error);
      return res.status(500).json({ message: 'Error al buscar el sitio en la base de datos' });
    }

    // Generar claveUnica
    const claveUnica = `${nombrePelicula}-${new Date(fechaHora).toISOString()}-${sitio}`;

    const newProjection = new Projection({
      nombrePelicula,
      fechaHora,
      sitio,
      director,
      genero,
      duracion,
      sala,
      precio,
      cargaManual: true,
      nombreCine: siteInfo.nombre,
      claveUnica
    });

    const savedProjection = await newProjection.save();
    res.status(201).json(savedProjection);
  } catch (error) {
    console.error('Error al crear la proyección:', error);
    res.status(500).json({ message: 'Error interno del servidor al crear la proyección' });
  }
});

router.get('/proyecciones-actuales', async (req, res) => {
  try {
    const fechaActual = new Date();
    const projections = await Projection.find({
      habilitado: true,
      fechaHora: { $gte: fechaActual }
    }).sort({ fechaHora: 1 });
    res.status(200).json(projections);
  } catch (error) {
    res.status(500).json({ message: error.message });
  }
});

router.get('/proyecciones-anteriores', async (req, res) => {
  try {
    const fechaActual = new Date();
    const projections = await Projection.find({
      habilitado: true,
      fechaHora: { $lt: fechaActual }
    }).sort({ fechaHora: -1 });
    res.status(200).json(projections);
  } catch (error) {
    res.status(500).json({ message: error.message });
  }
});


router.post('/load-from-file', async (req, res) => {
  try {
    const { fileUrl, sitioId, fileType } = req.body;
    let projections;

    const site = await Site.findById(sitioId);
    if (!site) {
      return res.status(404).json({ message: 'Sitio no encontrado' });
    }

    if (fileType === 'image') {
      projections = await ImageScrapingService.scrapeFromImage(fileUrl, sitioId);
    } else if (fileType === 'pdf') {
      projections = await PDFScrapingService.scrapeFromPDF(fileUrl, sitioId);
    } else {
      return res.status(400).json({ message: 'Tipo de archivo no soportado' });
    }
    
    if (projections.length === 0) {
      return res.status(404).json({ message: 'No se encontraron proyecciones en el archivo' });
    }

    res.status(200).json(projections);
  } catch (error) {
    console.error('Error al cargar proyecciones desde archivo:', error);
    res.status(400).json({ message: error.message });
  }
});

// Obtener todas las proyecciones habilitadas
router.get('/', async (req, res) => {
  try {
    const projections = await Projection.find({ habilitado: true });
    res.status(200).json(projections);
  } catch (error) {
    res.status(500).json({ message: error.message });
  }
});

// Actualizar una proyección
router.put('/:id', async (req, res) => {
  try {
    const updatedProjection = await Projection.findByIdAndUpdate(
      req.params.id,
      req.body,
      { new: true }
    );
    if (!updatedProjection) {
      return res.status(404).json({ message: 'Proyección no encontrada' });
    }
    res.status(200).json(updatedProjection);
  } catch (error) {
    res.status(400).json({ message: error.message });
  }
});

// Deshabilitar una proyección (soft delete)
router.put('/disable/:id', async (req, res) => {
  try {
    const updatedProjection = await Projection.findByIdAndUpdate(
      req.params.id,
      { habilitado: false },
      { new: true }
    );
    if (!updatedProjection) {
      return res.status(404).json({ message: 'Proyección no encontrada' });
    }
    res.status(200).json(updatedProjection);
  } catch (error) {
    res.status(400).json({ message: error.message });
  }
});

// Habilitar una proyección
router.put('/enable/:id', async (req, res) => {
  try {
    const updatedProjection = await Projection.findByIdAndUpdate(
      req.params.id,
      { habilitado: true },
      { new: true }
    );
    if (!updatedProjection) {
      return res.status(404).json({ message: 'Proyección no encontrada' });
    }
    res.status(200).json(updatedProjection);
  } catch (error) {
    res.status(400).json({ message: error.message });
  }
});

//Ruta para exportar CSV
router.get('/exportar-csv', async (req, res) => {
  try {
    const { tipo } = req.query;
    let projections;
    const fechaActual = new Date();

    if (tipo === 'actual') {
      projections = await Projection.find({
        fechaHora: { $gte: fechaActual },
        habilitado: true
      }).populate('sitio', 'nombre');
    } else {
      projections = await Projection.find({ habilitado: true }).populate('sitio', 'nombre');
    }

    const fields = ['nombrePelicula', 'fechaHora', 'director', 'genero', 'duracion', 'sala', 'precio', 'nombreCine'];
    const opts = { fields };
    const parser = new Parser(opts);

    const csv = parser.parse(projections.map(p => ({
      ...p.toObject(),
      nombreCine: p.nombreCine || (p.sitio && p.sitio.nombre) || 'No especificado',
      fechaHora: p.fechaHora.toLocaleString()
    })));

    res.header('Content-Type', 'text/csv');
    res.attachment(`cartelera_${tipo === 'actual' ? 'actual' : 'completa'}.csv`);
    res.send(csv);
  } catch (error) {
    console.error('Error al exportar a CSV:', error);
    res.status(500).json({ message: error.message });
  }
});

module.exports = router;

================
File: routes/site.routes.js
================
const express = require('express');
const Site = require('../models/site.model');
const ScrapingService = require('../services/scraping.service');
const ScrapingHistory = require('../models/scrapingHistory.model');
const router = express.Router();


router.post('/add', async (req, res) => {
  try {
    console.log('Datos recibidos en el servidor:', req.body); // Agregamos este log

    const { nombre, url, direccion, tipo, tipoCarga, frecuenciaActualizacion, usuarioCreador } = req.body;

    // Validación básica
    if (!nombre || !url || !tipoCarga || !usuarioCreador) {
      return res.status(400).json({ message: 'Faltan campos requeridos' });
    }

    // Validación adicional para tipoCarga 'scraping'
    if (tipoCarga === 'scraping' && !frecuenciaActualizacion) {
      return res.status(400).json({ message: 'La frecuencia de actualización es requerida para sitios de scraping' });
    }

    const newSite = new Site({
      nombre,
      url,
      direccion,
      tipo,
      tipoCarga,
      frecuenciaActualizacion,
      usuarioCreador,
      habilitado: true,
      activoParaScraping: tipoCarga === 'scraping'
    });

    const savedSite = await newSite.save();
    res.status(201).json(savedSite);
  } catch (error) {
    console.error('Error al guardar el sitio:', error);
    res.status(400).json({ message: error.message });
  }
});

router.get('/manual', async (req, res) => {
  try {
    const sitios = await Site.find({ tipoCarga: 'manual', habilitado: true });
    res.status(200).json(sitios);
  } catch (error) {
    console.error('Error al obtener sitios manuales:', error);
    res.status(500).json({ message: error.message });
  }
});

// Obtener el horario de scraping
router.get('/scraping-schedule', async (req, res) => {
  try {
    const schedule = await ScrapingService.getSchedule();
    res.status(200).json(schedule);
  } catch (error) {
    res.status(500).json({ message: error.message });
  }
});

// Obtener el historial de scraping
router.get('/scraping-history', async (req, res) => {
  try {
    const history = await ScrapingHistory.find().populate('siteId', 'nombre');
    res.status(200).json(history);
  } catch (error) {
    console.error('Error fetching scraping history:', error);
    res.status(500).json({ message: error.message });
  }
});

// Obtener todos los sitios habilitados
router.get('/', async (req, res) => {
  try {
    const sites = await Site.find({ habilitado: true });
    // Asegurarse de que siempre devolvamos un array
    res.status(200).json(sites || []);
  } catch (error) {
    console.error('Error al obtener sitios:', error);
    res.status(500).json({ message: error.message });
  }
});

// Actualizar un sitio
router.put('/:id', async (req, res) => {
  try {
    const { id } = req.params;
    const updateData = req.body;

    updateData.activoParaScraping = updateData.tipoCarga === 'scraping';

    if (updateData.tipoCarga === 'manual') {
      delete updateData.frecuenciaActualizacion;
    }

    const updatedSite = await Site.findByIdAndUpdate(
      id,
      updateData,
      { new: true, runValidators: true }
    );

    if (!updatedSite) {
      return res.status(404).json({ message: 'Sitio no encontrado' });
    }

    if (updatedSite.activoParaScraping) {
      ScrapingService.updateJob(updatedSite);
    } else {
      ScrapingService.removeJob(updatedSite._id);
    }

    res.status(200).json(updatedSite);
  } catch (error) {
    console.error('Error al actualizar el sitio:', error);
    res.status(400).json({ message: error.message });
  }
});

// Deshabilitar un sitio (soft delete)
router.put('/disable/:id', async (req, res) => {
  try {
    const updatedSite = await Site.findByIdAndUpdate(
      req.params.id,
      { habilitado: false },
      { new: true }
    );
    if (!updatedSite) {
      return res.status(404).json({ message: 'Sitio no encontrado' });
    }
    res.status(200).json(updatedSite);
  } catch (error) {
    res.status(400).json({ message: error.message });
  }
});

// Habilitar un sitio
router.put('/enable/:id', async (req, res) => {
  try {
    const updatedSite = await Site.findByIdAndUpdate(
      req.params.id,
      { habilitado: true },
      { new: true }
    );
    if (!updatedSite) {
      return res.status(404).json({ message: 'Sitio no encontrado' });
    }
    res.status(200).json(updatedSite);
  } catch (error) {
    res.status(400).json({ message: error.message });
  }
});

router.get('/scraping-diagnostic', async (req, res) => {
  try {
    const diagnosticInfo = await ScrapingService.getDiagnosticInfo();
    res.status(200).json(diagnosticInfo);
  } catch (error) {
    console.error('Error al obtener información de diagnóstico:', error);
    res.status(500).json({ message: error.message });
  }
});

module.exports = router;

================
File: routes/stats.routes.js
================
const express = require('express');
const router = express.Router();
const Site = require('../models/site.model');
const Projection = require('../models/projection.model');
const ScrapingHistory = require('../models/scrapingHistory.model');
const ScrapingService = require('../services/scraping.service');

router.get('/', async (req, res) => {
  try {
    console.log('Iniciando obtención de estadísticas');

    const sitiosAgregados = await Site.countDocuments({ habilitado: true });
    console.log('Sitios agregados:', sitiosAgregados);

    const funcionesScrapeadas = await Projection.countDocuments({ habilitado: true });
    console.log('Funciones scrapeadas:', funcionesScrapeadas);
    
    // Obtener el próximo scraping programado
    const proximoScrapingInfo = await ScrapingService.obtenerProximoScraping();
    const proximoScraping = proximoScrapingInfo ? 
      `${proximoScrapingInfo.nombre} (${new Date(proximoScrapingInfo.fechaScraping).toLocaleString()})` : 
      'No programado';
    console.log('Próximo scraping:', proximoScraping);

    const ultimoScrapingExitoso = await ScrapingHistory.findOne({ estado: 'exitoso' })
      .sort({ fechaScraping: -1 })
      .populate('siteId', 'nombre');
    console.log('Último scraping exitoso:', ultimoScrapingExitoso);

    const ultimosScrapings = await ScrapingHistory.find({
      fechaScraping: { $gte: new Date(Date.now() - 7 * 24 * 60 * 60 * 1000) }
    });
    console.log('Últimos scrapings:', ultimosScrapings.length);
    
    const tasaExitoScraping = ultimosScrapings.length > 0
      ? (ultimosScrapings.filter(s => s.estado === 'exitoso').length / ultimosScrapings.length * 100).toFixed(2)
      : 0;
    console.log('Tasa de éxito de scraping:', tasaExitoScraping);

    const sitioMasActivo = await Projection.aggregate([
      { $group: { _id: '$sitio', count: { $sum: 1 } } },
      { $sort: { count: -1 } },
      { $limit: 1 }
    ]);
    console.log('Sitio más activo:', sitioMasActivo);

    let sitioMasActivoNombre = 'N/A';
    if (sitioMasActivo.length > 0) {
      const sitio = await Site.findById(sitioMasActivo[0]._id);
      sitioMasActivoNombre = sitio ? sitio.nombre : 'N/A';
    }
    console.log('Nombre del sitio más activo:', sitioMasActivoNombre);

    res.json({
      sitiosAgregados,
      funcionesScrapeadas,
      proximoScraping,
      ultimoScrapingExitoso: ultimoScrapingExitoso
        ? `${ultimoScrapingExitoso.siteId.nombre} (${new Date(ultimoScrapingExitoso.fechaScraping).toLocaleString()})`
        : 'N/A',
      tasaExitoScraping,
      sitioMasActivo: sitioMasActivoNombre
    });

    console.log('Estadísticas enviadas con éxito');
  } catch (error) {
    console.error('Error detallado al obtener estadísticas:', error);
    res.status(500).json({ 
      message: 'Error al obtener estadísticas', 
      error: error.message,
      stack: error.stack 
    });
  }
});

module.exports = router;

================
File: services/imagescraping.service.js
================
const axios = require('axios');
const Site = require('../models/site.model');
const Projection = require('../models/projection.model');
const ScrapingHistory = require('../models/scrapingHistory.model');
require('dotenv').config();

class ImageScrapingService {
  constructor() {
    this.openaiApiKey = process.env.OPENAI_API_KEY;
  }

  async scrapeFromImage(imageUrl, sitioId) {
    console.log(`Iniciando scraping desde imagen para el sitio ID: ${sitioId}`);
    try {
      const site = await Site.findById(sitioId);
      if (!site) {
        throw new Error('Sitio no encontrado');
      }

      const projections = await this.openAIScrapeImage(imageUrl);

      if (projections.length > 0) {
        console.log(`${projections.length} proyecciones extraídas de la imagen para ${site.nombre}`);
        await this.updateSiteAndHistory(sitioId, 'exitoso', null, projections.length);

        // Añadir claveUnica y nombreCine a cada proyección
        const projectionsWithUniqueKey = projections.map(p => ({
          ...p,
          sitio: sitioId,
          nombreCine: site.nombre,
          claveUnica: `${p.nombrePelicula}-${p.fechaHora.toISOString()}-${sitioId}`
        }));

        return projectionsWithUniqueKey;
      } else {
        console.log(`No se encontraron proyecciones en la imagen para el sitio ${site.nombre}`);
        await this.updateSiteAndHistory(sitioId, 'exitoso', 'No se encontraron proyecciones', 0);
        return [];
      }
    } catch (error) {
      console.error(`Error al hacer scraping de la imagen para el sitio ${sitioId}:`, error);
      await this.updateSiteAndHistory(sitioId, 'fallido', error.message, 0);
      throw error;
    }
  }

  async openAIScrapeImage(imageUrl) {
    console.log('Ejecutando análisis basado en OpenAI para la imagen');
    
    const prompt = `Analiza la siguiente imagen de una cartelera de cine o teatro y extrae información sobre las proyecciones de cine unicamente:

    Incluye el nombre de la película o evento, la fecha y hora, el director (si está disponible), el género, la duración, la sala y el precio. Devuelve la información en formato JSON siguiendo este esquema:
    {
      "proyecciones": [
        {
          "nombre": "string",
          "fechaHora": "string (formato ISO)",
          "director": "string",
          "genero": "string",
          "duracion": number,
          "sala": "string",
          "precio": number
        }
      ]
    }
    Si no encuentras nada, devuelve un array vacío. Asume que la funcion es en el año actual (2024) salvo que se exprese lo contrario. Devuelve SOLO el JSON con los datos en propercase, sin ningún otro texto o formato adicional.`;

    try {
      const response = await axios.post(
        'https://api.openai.com/v1/chat/completions',
        {
          model: "gpt-4o-mini",
          messages: [
            {
              role: "system",
              content: "Eres un experto en extraer información sobre proyecciones de cine y teatro desde imágenes. Tu tarea es analizar la imagen proporcionada y extraer información sobre las proyecciones o eventos. Devuelve SOLO el JSON sin ningún otro texto o formato adicional."
            },
            {
              role: "user",
              content: [
                { type: "text", text: prompt },
                { type: "image_url", image_url: { url: imageUrl } }
              ]
            }
          ],
          max_tokens: 4000
        },
        {
          headers: {
            'Authorization': `Bearer ${this.openaiApiKey}`,
            'Content-Type': 'application/json'
          }
        }
      );

      let content = response.data.choices[0]?.message?.content.trim() || "{}";
      content = content.replace(/```json\n?|\n?```/g, '').trim();
      
      let aiResponse;
      try {
        aiResponse = JSON.parse(content);
      } catch (parseError) {
        console.error('Error al parsear la respuesta de OpenAI:', parseError);
        throw new Error(`No se pudo parsear la respuesta de OpenAI: ${parseError.message}`);
      }
      
      const proyecciones = aiResponse.proyecciones || aiResponse.Proyecciones;
      if (!Array.isArray(proyecciones)) {
        console.error('Respuesta de OpenAI no contiene proyecciones válidas:', aiResponse);
        throw new Error('Respuesta de OpenAI no contiene proyecciones válidas');
      }

      return this.processAIResponse(proyecciones);
    } catch (error) {
      console.error('Error en OpenAI scrape de imagen:', error);
      throw error;
    }
  }

  processAIResponse(proyecciones) {
    return proyecciones.map(p => ({
      nombrePelicula: p.nombre || p.Nombre,
      fechaHora: new Date(p.fechaHora || p.FechaHora),
      director: p.director || p.Director || 'No especificado',
      genero: p.genero || p.Genero || 'No especificado',
      duracion: parseInt(p.duracion || p.Duracion) || 0,
      sala: p.sala || p.Sala || 'No especificada',
      precio: parseFloat(p.precio || p.Precio) || 0
    })).filter(p => p.nombrePelicula && p.fechaHora && !isNaN(p.fechaHora.getTime()));
  }

  async updateSiteAndHistory(siteId, estado, mensajeError, cantidadProyecciones) {
    await Site.findByIdAndUpdate(siteId, {
      $set: { 'configuracionScraping.ultimoScrapingExitoso': new Date() },
      $push: { 'configuracionScraping.errores': { fecha: new Date(), mensaje: mensajeError } }
    });

    await ScrapingHistory.create({
      siteId,
      estado,
      mensajeError,
      cantidadProyecciones
    });
  }
}

module.exports = new ImageScrapingService();

================
File: services/pdfscraping.service.js
================
const axios = require('axios');
const pdf = require('pdf-parse');
const Site = require('../models/site.model');
const Projection = require('../models/projection.model');
const ScrapingHistory = require('../models/scrapingHistory.model');
require('dotenv').config();

class PDFScrapingService {
  constructor() {
    this.openaiApiKey = process.env.OPENAI_API_KEY;
  }

  async scrapeFromPDF(pdfUrl, sitioId) {
    console.log(`Iniciando scraping desde PDF para el sitio ID: ${sitioId}`);
    try {
      const site = await Site.findById(sitioId);
      if (!site) {
        throw new Error('Sitio no encontrado');
      }

      const pdfContent = await this.extractPDFContent(pdfUrl);
      const projections = await this.openAIScrapePDF(pdfContent);

      if (projections.length > 0) {
        console.log(`${projections.length} proyecciones extraídas del PDF para ${site.nombre}`);
        await this.updateSiteAndHistory(sitioId, 'exitoso', null, projections.length);

        const projectionsWithUniqueKey = projections.map(p => ({
          ...p,
          sitio: sitioId,
          nombreCine: site.nombre,
          claveUnica: `${p.nombrePelicula}-${p.fechaHora.toISOString()}-${sitioId}`
        }));

        return projectionsWithUniqueKey;
      } else {
        console.log(`No se encontraron proyecciones en el PDF para el sitio ${site.nombre}`);
        await this.updateSiteAndHistory(sitioId, 'exitoso', 'No se encontraron proyecciones', 0);
        return [];
      }
    } catch (error) {
      console.error(`Error al hacer scraping del PDF para el sitio ${sitioId}:`, error);
      await this.updateSiteAndHistory(sitioId, 'fallido', error.message, 0);
      throw error;
    }
  }

  async extractPDFContent(pdfUrl) {
    const response = await axios.get(pdfUrl, { responseType: 'arraybuffer' });
    const pdfBuffer = Buffer.from(response.data);
    const data = await pdf(pdfBuffer);
    return data.text;
  }

  async openAIScrapePDF(pdfContent) {
    console.log('Ejecutando análisis basado en OpenAI para el PDF');
    
    const prompt = `Analiza el siguiente contenido extraído de un PDF de una cartelera de cine o teatro y extrae información sobre las proyecciones de cine únicamente:

    ${pdfContent}

    Incluye el nombre de la película o evento, la fecha y hora, el director (si está disponible), el género, la duración, la sala y el precio. Devuelve la información en formato JSON siguiendo este esquema:
    {
      "proyecciones": [
        {
          "nombre": "string",
          "fechaHora": "string (formato ISO)",
          "director": "string",
          "genero": "string",
          "duracion": number,
          "sala": "string",
          "precio": number
        }
      ]
    }
    Si no encuentras nada, devuelve un array vacío. Asume que la funcion es en el año actual (2024) salvo que se exprese lo contrario. Devuelve SOLO el JSON con los datos en propercase, sin ningún otro texto o formato adicional.`;

    try {
      const response = await axios.post(
        'https://api.openai.com/v1/chat/completions',
        {
          model: "gpt-4o-mini",
          messages: [
            {
              role: "system",
              content: "Eres un experto en extraer información sobre proyecciones de cine y teatro desde PDFs. Tu tarea es analizar el contenido del PDF proporcionado y extraer información sobre las proyecciones o eventos. Devuelve SOLO el JSON sin ningún otro texto o formato adicional."
            },
            {
              role: "user",
              content: prompt
            }
          ],
          max_tokens: 4000
        },
        {
          headers: {
            'Authorization': `Bearer ${this.openaiApiKey}`,
            'Content-Type': 'application/json'
          }
        }
      );

      let content = response.data.choices[0]?.message?.content.trim() || "{}";
      content = content.replace(/```json\n?|\n?```/g, '').trim();
      
      let aiResponse;
      try {
        aiResponse = JSON.parse(content);
      } catch (parseError) {
        console.error('Error al parsear la respuesta de OpenAI:', parseError);
        throw new Error(`No se pudo parsear la respuesta de OpenAI: ${parseError.message}`);
      }
      
      const proyecciones = aiResponse.proyecciones || aiResponse.Proyecciones;
      if (!Array.isArray(proyecciones)) {
        console.error('Respuesta de OpenAI no contiene proyecciones válidas:', aiResponse);
        throw new Error('Respuesta de OpenAI no contiene proyecciones válidas');
      }

      return this.processAIResponse(proyecciones);
    } catch (error) {
      console.error('Error en OpenAI scrape de PDF:', error);
      throw error;
    }
  }

  processAIResponse(proyecciones) {
    const currentYear = new Date().getFullYear();
    const nextYear = currentYear + 1;

    return proyecciones.map(p => {
      let fechaHora = new Date(p.fechaHora || p.FechaHora);
    
      if (fechaHora < new Date()) {
        fechaHora.setFullYear(nextYear);
      } else {
        fechaHora.setFullYear(Math.max(fechaHora.getFullYear(), currentYear));
      }

      return {
        nombrePelicula: p.nombre || p.Nombre,
        fechaHora: fechaHora,
        director: p.director || p.Director || 'No especificado',
        genero: p.genero || p.Genero || 'No especificado',
        duracion: parseInt(p.duracion || p.Duracion) || 0,
        sala: p.sala || p.Sala || 'No especificada',
        precio: parseFloat(p.precio || p.Precio) || 0
      };
    }).filter(p => p.nombrePelicula && p.fechaHora && !isNaN(p.fechaHora.getTime()));
  }

  async updateSiteAndHistory(siteId, estado, mensajeError, cantidadProyecciones) {
    await Site.findByIdAndUpdate(siteId, {
      $set: { 'configuracionScraping.ultimoScrapingExitoso': new Date() },
      $push: { 'configuracionScraping.errores': { fecha: new Date(), mensaje: mensajeError } }
    });

    await ScrapingHistory.create({
      siteId,
      estado,
      mensajeError,
      cantidadProyecciones
    });
  }
}

module.exports = new PDFScrapingService();

================
File: services/scraping.service.js
================
const puppeteer = require('puppeteer-core');
const chromium = require('chrome-aws-lambda');
const axios = require('axios');
const cheerio = require('cheerio');
const cron = require('node-cron');
const Site = require('../models/site.model');
const Projection = require('../models/projection.model');
const ScrapingHistory = require('../models/scrapingHistory.model');

require('dotenv').config();

class ScrapingService {
  constructor() {
    this.jobs = {};
    this.openaiApiKey = process.env.OPENAI_API_KEY;
    this.lastRunTimes = {};
    this.nextScheduledRuns = {};
    this.isVercelEnvironment = process.env.VERCEL_ENV !== undefined;
    console.log(`Entorno de ejecución: ${this.isVercelEnvironment ? 'Vercel' : 'No Vercel'}`);
  }

  async initializeJobs() {
    console.log('Iniciando inicialización de trabajos de scraping...');
    const sites = await Site.find({ activoParaScraping: true });
    sites.forEach(site => this.scheduleJob(site));
    console.log(`Inicializados ${sites.length} trabajos de scraping.`);

    this.setupSiteChangeObserver();
    console.log('Observador de cambios de sitios configurado.');

    if (this.isVercelEnvironment) {
      this.setupPeriodicCheck();
    }
  }

  setupPeriodicCheck() {
    setInterval(async () => {
      console.log('Realizando verificación periódica de jobs...');
      const sites = await Site.find({ activoParaScraping: true });
      sites.forEach(site => {
        const now = new Date();
        const lastRun = this.lastRunTimes[site._id];
        const timeSinceLastRun = lastRun ? (now - lastRun) / 1000 : Infinity;

        console.log(`Sitio ${site.nombre}: Última ejecución hace ${timeSinceLastRun} segundos`);

        if (this.shouldRunScraping(site, timeSinceLastRun)) {
          console.log(`Ejecutando scraping para ${site.nombre}`);
          this.scrapeSite(site);
        }
      });
    }, 60000); // Verificar cada minuto
  }

  shouldRunScraping(site, timeSinceLastRun) {
    switch (site.frecuenciaActualizacion) {
      case 'test':
        return timeSinceLastRun > 60; // Cada minuto
      case 'diaria':
        return timeSinceLastRun > 86400; // 24 horas
      case 'semanal':
        return timeSinceLastRun > 604800; // 7 días
      case 'mensual':
        return timeSinceLastRun > 2592000; // 30 días
      default:
        return false;
    }
  }

  scheduleJob(site) {
    console.log(`Programando job para ${site.nombre}`);
    this.jobs[site._id] = {
      site: site,
      lastRun: null
    };

    if (site.frecuenciaActualizacion === 'test') {
      console.log(`Forzando ejecución inmediata para ${site.nombre}`);
      this.scrapeSite(site);
    }
  }

  async scrapeSite(site) {
    console.log(`==================== INICIO DE SCRAPING PARA ${site.nombre} ====================`);
    console.log(`Iniciando scraping para ${site.nombre} (${site.url}) en ${new Date().toISOString()}`);
    this.lastRunTimes[site._id] = new Date();
    let browser;
    let respuestaOpenAI = '';
    let causaFallo = '';
    try {
      browser = await puppeteer.launch({
        args: chromium.args,
        defaultViewport: chromium.defaultViewport,
        executablePath: await chromium.executablePath,
        headless: chromium.headless,
        ignoreHTTPSErrors: true,
      });
      const page = await browser.newPage();
      
      await page.goto(site.url, { 
        waitUntil: 'networkidle0',
        timeout: 30000
      });

      const htmlContent = await page.content();
      await browser.close();

      const extractedInfo = this.extractBasicInfo(htmlContent);
      const openAIResponse = await this.openAIScrape(site, extractedInfo);
      respuestaOpenAI = JSON.stringify(openAIResponse);
      console.log('Respuesta de OpenAI:', respuestaOpenAI);

      let proyecciones = openAIResponse.proyecciones || openAIResponse.Proyecciones;
      if (!Array.isArray(proyecciones)) {
        causaFallo = 'La respuesta de OpenAI no contiene un array de proyecciones válido';
        console.error(causaFallo);
        throw new Error(causaFallo);
      }

      const projections = this.processAIResponse(proyecciones, site._id);

      if (projections.length > 0) {
        try {
          await this.insertProjections(projections, site);
          console.log(`${projections.length} proyecciones procesadas correctamente para ${site.nombre}`);
          await this.updateSiteAndHistory(site._id, 'exitoso', null, projections.length, respuestaOpenAI);
        } catch (dbError) {
          causaFallo = 'Error al procesar las proyecciones en la base de datos';
          console.error(causaFallo, dbError);
          throw new Error(`${causaFallo}: ${dbError.message}`);
        }
      } else {
        causaFallo = 'No se encontraron proyecciones válidas';
        console.log(causaFallo);
        await this.updateSiteAndHistory(site._id, 'exitoso', causaFallo, 0, respuestaOpenAI);
      }
    } catch (error) {
      causaFallo = `Error en scraping: ${error.message}`;
      console.error(`Error en scraping de ${site.nombre}:`, error);
      console.error('Stack trace completo:', error.stack);
      await this.updateSiteAndHistory(site._id, 'fallido', error.message, 0, respuestaOpenAI, causaFallo);
    } finally {
      if (browser && browser.isConnected()) {
        await browser.close();
      }
    }
    console.log(`==================== FIN DE SCRAPING PARA ${site.nombre} ====================`);
  }

  extractBasicInfo(htmlContent) {
    const $ = cheerio.load(htmlContent);
    let extractedText = '';

    $('body').find('*').each((index, element) => {
      if ($(element).is('script, style, meta, link')) return;

      const text = $(element).clone().children().remove().end().text().trim();
      if (text) {
        extractedText += `${text}\n`;
      }

      if ($(element).is('img')) {
        const alt = $(element).attr('alt');
        const src = $(element).attr('src');
        if (alt || src) {
          extractedText += `Imagen: ${alt || 'Sin descripción'} (${src})\n`;
        }
      }
    });

    return extractedText.trim();
  }

  async openAIScrape(site, extractedInfo) {
    const prompt = `Analiza el siguiente texto extraído de un sitio web de cine y extrae información sobre las proyecciones:

    ${extractedInfo}

    Devuelve un JSON con este formato:
    {
      "proyecciones": [
        {
          "nombre": "string",
          "fechaHora": "string (ISO)",
          "director": "string",
          "genero": "string",
          "duracion": number,
          "sala": "string",
          "precio": number
        }
      ]
    }
    Si no encuentras nada, devuelve un array vacío. Asume que el año es el actual (2024), salvo que sea explicito que no lo es. Devuelve SOLO el JSON con los titulos en propercase, sin ningún texto adicional ni marcadores de código como \`\`\`json.`;

    try {
      const response = await axios.post(
        'https://api.openai.com/v1/chat/completions',
        {
          model: "gpt-4o-mini",
          messages: [
            { role: "system", content: "Eres un experto en extraer información de cine de texto HTML. Tu tarea es analizar el texto proporcionado y extraer información sobre las proyecciones de películas." },
            { role: "user", content: prompt }
          ],
          temperature: 0.2,
          max_tokens: 8000
        },
        { headers: { 'Authorization': `Bearer ${this.openaiApiKey}`, 'Content-Type': 'application/json' } }
      );

      let content = response.data.choices[0]?.message?.content.trim() || "{}";
      content = content.replace(/```json\n?|\n?```/g, '').trim();

      let aiResponse = JSON.parse(content);
      console.log('Respuesta parseada de OpenAI:', aiResponse);
      return aiResponse;
    } catch (error) {
      console.error('Error en OpenAI scrape:', error);
      throw error;
    }
  }

  processAIResponse(proyecciones, siteId) {
    if (!Array.isArray(proyecciones)) {
      console.error('processAIResponse recibió proyecciones no válidas:', proyecciones);
      return [];
    }
    const currentYear = new Date().getFullYear();
    return proyecciones.map(p => {
      let fechaHora = new Date(p.fechaHora || p.FechaHora);
      
      if (fechaHora < new Date()) {
        fechaHora.setFullYear(currentYear);
      } else {
        fechaHora.setFullYear(Math.max(fechaHora.getFullYear(), currentYear));
      }

      return {
        nombrePelicula: p.nombre || p.Nombre,
        fechaHora: fechaHora,
        director: p.director || p.Director || 'No especificado',
        genero: p.genero || p.Genero || 'No especificado',
        duracion: parseInt(p.duracion || p.Duracion) || 0,
        sala: p.sala || p.Sala || 'No especificada',
        precio: parseFloat(p.precio || p.Precio) || 0,
        sitio: siteId
      };
    }).filter(p => p.nombrePelicula && p.fechaHora && !isNaN(p.fechaHora.getTime()));
  }

  async insertProjections(projections, site) {
    for (const projection of projections) {
      try {
        const claveUnica = `${projection.nombrePelicula}-${projection.fechaHora.toISOString()}-${site._id}`;
        await Projection.findOneAndUpdate(
          { claveUnica },
          { 
            ...projection, 
            sitio: site._id, 
            nombreCine: site.nombre,
            claveUnica
          },
          { upsert: true, new: true, setDefaultsOnInsert: true }
        );
      } catch (error) {
        if (error.code === 11000) {
          console.log(`Proyección duplicada ignorada: ${projection.nombrePelicula} en ${site.nombre} a las ${projection.fechaHora}`);
        } else {
          console.error('Error al insertar/actualizar proyección:', error);
          throw error;
        }
      }
    }
  }

  async updateSiteAndHistory(siteId, estado, mensajeError, cantidadProyecciones, respuestaOpenAI, causaFallo = '') {
    await Site.findByIdAndUpdate(siteId, {
      $set: { 'configuracionScraping.ultimoScrapingExitoso': new Date() },
      $push: { 'configuracionScraping.errores': { fecha: new Date(), mensaje: mensajeError } }
    });

    await ScrapingHistory.create({
      siteId,
      estado,
      mensajeError,
      cantidadProyecciones,
      respuestaOpenAI,
      causaFallo
    });
  }

  updateJob(site) {
    if (site.activoParaScraping) {
      this.scheduleJob(site);
    } else {
      this.removeJob(site._id);
    }
  }

  removeJob(siteId) {
    if (this.jobs[siteId]) {
      this.jobs[siteId].stop();
      delete this.jobs[siteId];
      console.log(`Job removido para el sitio con ID: ${siteId}`);
    }
  }

  async getSchedule() {
    const sites = await Site.find({ activoParaScraping: true });
    const now = new Date();
    return sites.flatMap(site => 
      Array.from({ length: 10 }, (_, i) => {
        const date = this.calcularProximoScraping(site, now, i);
        return {
          siteId: site._id,
          nombre: site.nombre,
          frecuencia: site.frecuenciaActualizacion,
          fechaScraping: date
        };
      })
    ).sort((a, b) => a.fechaScraping - b.fechaScraping);
  }

  calcularProximoScraping(site, fromDate) {
    const date = new Date(fromDate);
    const ahora = new Date();
    
    switch (site.frecuenciaActualizacion) {
      case 'diaria':
        date.setHours(0, 0, 0, 0);
        if (date <= ahora) {
          date.setDate(date.getDate() + 1);
        }
        break;
      case 'semanal':
        date.setHours(0, 0, 0, 0);
        while (date <= ahora) {
          date.setDate(date.getDate() + 7);
        }
        break;
      case 'mensual':
        date.setDate(1);
        date.setHours(0, 0, 0, 0);
        while (date <= ahora) {
          date.setMonth(date.getMonth() + 1);
        }
        break;
      case 'test':
        date.setMinutes(date.getMinutes() + 1);
        break;
      default:
        console.error(`Frecuencia de actualización no válida: ${site.frecuenciaActualizacion}`);
        return null;
    }
    
    return date;
  }

  async obtenerProximoScraping() {
    const sitios = await Site.find({ activoParaScraping: true });
    const ahora = new Date();
    let proximoScraping = null;

    for (const sitio of sitios) {
      const proximaFecha = this.calcularProximoScraping(sitio, ahora);
      if (proximaFecha && (!proximoScraping || proximaFecha < proximoScraping.fechaScraping)) {
        proximoScraping = {
          nombre: sitio.nombre,
          fechaScraping: proximaFecha
        };
      }
    }

    return proximoScraping;
  }

  async getDiagnosticInfo() {
    console.log('Obteniendo información de diagnóstico de scraping...');
    const sites = await Site.find({ activoParaScraping: true });
    return sites.map(site => {
      const jobInfo = this.jobs[site._id];
      const lastRun = this.lastRunTimes[site._id];
      const nextRun = this.nextScheduledRuns[site._id];
      return {
        id: site._id,
        nombre: site.nombre,
        frecuencia: site.frecuenciaActualizacion,
        ultimaEjecucion: lastRun ? lastRun.toISOString() : 'Nunca',
        tiempoDesdeUltimaEjecucion: lastRun ? `${Math.round((new Date() - lastRun) / 1000)} segundos` : 'N/A',
        jobActivo: !!jobInfo,
        proximaEjecucion: nextRun ? nextRun.toISOString() : 'No programado',
        expresionCron: this.getCronExpression(site.frecuenciaActualizacion),
        entorno: this.isVercelEnvironment ? 'Vercel' : 'Desarrollo local'
      };
    });
    
  }
  setupSiteChangeObserver() {
    console.log('Observador de cambios de sitios configurado.');
    // Implementar la lógica del observador si es necesaria
  }
}

module.exports = new ScrapingService();

================
File: vercel.json
================
{
  "version": 2,
  "builds": [
    {
      "src": "server/api/index.js",
      "use": "@vercel/node"
    }
  ],
  "routes": [
    {
      "src": "/api/(.*)",
      "dest": "server/api/index.js"
    }
  ]
}
